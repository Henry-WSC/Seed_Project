{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3a55673-cdac-4246-8cb2-625d08cbe983",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\henry\\anaconda3\\envs\\seed_project\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: torch in c:\\users\\henry\\anaconda3\\envs\\seed_project\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\henry\\anaconda3\\envs\\seed_project\\lib\\site-packages (0.19.1)\n",
      "Requirement already satisfied: pycocotools in c:\\users\\henry\\anaconda3\\envs\\seed_project\\lib\\site-packages (2.0.8)\n",
      "Requirement already satisfied: pillow in c:\\users\\henry\\anaconda3\\envs\\seed_project\\lib\\site-packages (10.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\henry\\anaconda3\\envs\\seed_project\\lib\\site-packages (from scikit-learn) (2.1.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\henry\\anaconda3\\envs\\seed_project\\lib\\site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\henry\\anaconda3\\envs\\seed_project\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\henry\\anaconda3\\envs\\seed_project\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\henry\\anaconda3\\envs\\seed_project\\lib\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\henry\\anaconda3\\envs\\seed_project\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\henry\\anaconda3\\envs\\seed_project\\lib\\site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\henry\\anaconda3\\envs\\seed_project\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\henry\\anaconda3\\envs\\seed_project\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\henry\\anaconda3\\envs\\seed_project\\lib\\site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\henry\\anaconda3\\envs\\seed_project\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: matplotlib>=2.1.0 in c:\\users\\henry\\anaconda3\\envs\\seed_project\\lib\\site-packages (from pycocotools) (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\henry\\anaconda3\\envs\\seed_project\\lib\\site-packages (from matplotlib>=2.1.0->pycocotools) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\henry\\anaconda3\\envs\\seed_project\\lib\\site-packages (from matplotlib>=2.1.0->pycocotools) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\henry\\anaconda3\\envs\\seed_project\\lib\\site-packages (from matplotlib>=2.1.0->pycocotools) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\henry\\anaconda3\\envs\\seed_project\\lib\\site-packages (from matplotlib>=2.1.0->pycocotools) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\henry\\anaconda3\\envs\\seed_project\\lib\\site-packages (from matplotlib>=2.1.0->pycocotools) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\henry\\anaconda3\\envs\\seed_project\\lib\\site-packages (from matplotlib>=2.1.0->pycocotools) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\henry\\anaconda3\\envs\\seed_project\\lib\\site-packages (from matplotlib>=2.1.0->pycocotools) (2.9.0.post0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\henry\\anaconda3\\envs\\seed_project\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\henry\\anaconda3\\envs\\seed_project\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\henry\\anaconda3\\envs\\seed_project\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# Instalaci√≥n de paquetes necesarios\n",
    "!pip install scikit-learn torch torchvision pycocotools pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f344a62-8c15-4726-af4d-56628251c71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librer√≠as\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pycocotools.coco import COCO\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.models.detection import maskrcnn_resnet50_fpn\n",
    "from torchvision.utils import draw_segmentation_masks\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection import maskrcnn_resnet50_fpn\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pycocotools.coco import COCO\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection import maskrcnn_resnet50_fpn\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from pycocotools.coco import COCO\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60ae58fb-0468-46aa-a039-fccc7435d1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Configuraci√≥n de dispositivo (GPU si est√° disponible, sino CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bfcca17-d2d8-480c-8cc9-a78e58f537f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definici√≥n de rutas\n",
    "coco_file_path = r'C:\\Users\\HENRY\\Documents\\Seed_Project\\Project_germination\\result.json'\n",
    "image_dir = r'C:\\Users\\HENRY\\Documents\\Seed_Project\\Project_germination\\images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2eb22f90-a2d5-49a4-8141-dd28f42bb8eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=1.05s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# Cargar las anotaciones COCO\n",
    "coco = COCO(coco_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed3180fb-0cf4-4d4e-b7ed-d6b4890b1a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener todos los IDs de las im√°genes\n",
    "img_ids = list(coco.imgs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf7c9a0c-ec0a-4182-a763-5aff4f76d9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total im√°genes: 159\n",
      "Im√°genes de entrenamiento: 111 (69.81%)\n",
      "Im√°genes de validaci√≥n: 32 (20.13%)\n",
      "Im√°genes de prueba: 16 (10.06%)\n"
     ]
    }
   ],
   "source": [
    "# Dividir los datos: 70% entrenamiento, 20% validaci√≥n, 10% prueba\n",
    "train_ids, temp_ids = train_test_split(img_ids, test_size=0.3, random_state=42)\n",
    "val_ids, test_ids = train_test_split(temp_ids, test_size=0.33, random_state=42)\n",
    "\n",
    "print(f\"Total im√°genes: {len(img_ids)}\")\n",
    "print(f\"Im√°genes de entrenamiento: {len(train_ids)} ({len(train_ids)/len(img_ids)*100:.2f}%)\")\n",
    "print(f\"Im√°genes de validaci√≥n: {len(val_ids)} ({len(val_ids)/len(img_ids)*100:.2f}%)\")\n",
    "print(f\"Im√°genes de prueba: {len(test_ids)} ({len(test_ids)/len(img_ids)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "721c958f-6d8f-4fff-8049-d6b150640c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificaci√≥n de las rutas\n",
    "if not os.path.exists(coco_file_path):\n",
    "    print(f\"Error: No se encuentra el archivo JSON en: {coco_file_path}\")\n",
    "if not os.path.exists(image_dir):\n",
    "    print(f\"Error: No se encuentra el directorio de im√°genes en: {image_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f3fa265-cd99-4712-99a7-4e6078bb90dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ El archivo JSON existe en: C:\\Users\\HENRY\\Documents\\Seed_Project\\Project_germination\\result.json\n",
      "‚úÖ El directorio de im√°genes existe en: C:\\Users\\HENRY\\Documents\\Seed_Project\\Project_germination\\images\n",
      "üéâ Todas las rutas son correctas. Puedes proceder con tu modelo.\n"
     ]
    }
   ],
   "source": [
    "# Verificaci√≥n expl√≠cita de las rutas\n",
    "import os\n",
    "\n",
    "def verificar_ruta(ruta, tipo):\n",
    "    if os.path.exists(ruta):\n",
    "        print(f\"‚úÖ El {tipo} existe en: {ruta}\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"‚ùå Error: No se encuentra el {tipo} en: {ruta}\")\n",
    "        return False\n",
    "\n",
    "# Verificar el archivo JSON\n",
    "json_existe = verificar_ruta(coco_file_path, \"archivo JSON\")\n",
    "\n",
    "# Verificar el directorio de im√°genes\n",
    "imagenes_existen = verificar_ruta(image_dir, \"directorio de im√°genes\")\n",
    "\n",
    "if json_existe and imagenes_existen:\n",
    "    print(\"üéâ Todas las rutas son correctas. Puedes proceder con tu modelo.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Hay problemas con las rutas. Por favor, verifica y corrige antes de continuar.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82b77244-c32d-4874-aea2-e7045fcfec14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definici√≥n del conjunto de datos personalizado\n",
    "class SeedDataset(Dataset):\n",
    "    def __init__(self, coco, image_dir, transforms=None):\n",
    "        self.coco = coco\n",
    "        self.image_dir = image_dir\n",
    "        self.transforms = transforms\n",
    "        self.ids = list(self.coco.imgs.keys())\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_id = self.ids[index]\n",
    "        ann_ids = self.coco.getAnnIds(imgIds=img_id)\n",
    "        anns = self.coco.loadAnns(ann_ids)\n",
    "        \n",
    "        img_info = self.coco.loadImgs(img_id)[0]\n",
    "        img_path = os.path.join(self.image_dir, img_info['file_name'])\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        \n",
    "        num_objs = len(anns)\n",
    "        boxes = []\n",
    "        masks = []\n",
    "        for i in range(num_objs):\n",
    "            xmin = anns[i]['bbox'][0]\n",
    "            ymin = anns[i]['bbox'][1]\n",
    "            xmax = xmin + anns[i]['bbox'][2]\n",
    "            ymax = ymin + anns[i]['bbox'][3]\n",
    "            boxes.append([xmin, ymin, xmax, ymax])\n",
    "            mask = self.coco.annToMask(anns[i])\n",
    "            masks.append(mask)\n",
    "        \n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        masks = torch.as_tensor(masks, dtype=torch.uint8)\n",
    "        \n",
    "        image_id = torch.tensor([img_id])\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
    "        \n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"masks\"] = masks\n",
    "        target[\"image_id\"] = image_id\n",
    "        target[\"area\"] = area\n",
    "        target[\"iscrowd\"] = iscrowd\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            img, target = self.transforms(img, target)\n",
    "        \n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "71ce3efb-20ce-4b18-acc3-e9d83e472f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n para obtener el modelo\n",
    "def get_model(num_classes):\n",
    "    model = maskrcnn_resnet50_fpn(pretrained=True)\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "    hidden_layer = 256\n",
    "    model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask, hidden_layer, num_classes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "332cc8c0-8415-460d-bbda-77839cae4791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.39s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# Preparaci√≥n de los datos\n",
    "coco = COCO(coco_file_path)\n",
    "dataset = SeedDataset(coco, image_dir)\n",
    "data_loader = DataLoader(dataset, batch_size=2, shuffle=True, num_workers=4, collate_fn=lambda x: tuple(zip(*x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72b34afb-d4a4-4850-a021-c7ebed22abd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n para seleccionar un subconjunto aleatorio de im√°genes\n",
    "def get_subset_indices(dataset, num_images):\n",
    "    return torch.randperm(len(dataset))[:num_images].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a8bd3900-a7fe-467d-ba46-6c76186814f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n para visualizar y exportar m√°scaras\n",
    "def visualize_and_export_masks(model, dataset, indices, output_dir):\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    for idx in indices:\n",
    "        image, target = dataset[idx]\n",
    "        image_tensor = torchvision.transforms.functional.to_tensor(image).unsqueeze(0).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            prediction = model(image_tensor)[0]\n",
    "        \n",
    "        image_np = image.numpy().transpose((1, 2, 0))\n",
    "        masks = prediction['masks'].cpu().numpy()\n",
    "        \n",
    "        plt.figure(figsize=(15, 5))\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(image_np)\n",
    "        plt.title('Original Image')\n",
    "        \n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(image_np)\n",
    "        for mask in masks:\n",
    "            plt.imshow(mask[0], alpha=0.5, cmap='jet')\n",
    "        plt.title('Predicted Masks')\n",
    "        \n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(image_np)\n",
    "        for mask in target['masks']:\n",
    "            plt.imshow(mask.numpy(), alpha=0.5, cmap='jet')\n",
    "        plt.title('Ground Truth Masks')\n",
    "        \n",
    "        plt.savefig(os.path.join(output_dir, f'mask_comparison_{idx}.png'))\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "12253d41-276c-4123-8437-1ed9482f8944",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m Subset(dataset, val_indices)\n\u001b[0;32m      7\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m Subset(dataset, test_indices)\n\u001b[1;32m----> 9\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(train_dataset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, collate_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mx)))\n\u001b[0;32m     10\u001b[0m val_loader \u001b[38;5;241m=\u001b[39m DataLoader(val_dataset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, collate_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mx)))\n\u001b[0;32m     11\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m DataLoader(test_dataset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, collate_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mx)))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'batch_size' is not defined"
     ]
    }
   ],
   "source": [
    "# Dividir los datos en conjuntos de entrenamiento, validaci√≥n y prueba\n",
    "train_indices, temp_indices = train_test_split(range(len(dataset)), test_size=0.3, random_state=42)\n",
    "val_indices, test_indices = train_test_split(temp_indices, test_size=0.33, random_state=42)\n",
    "\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "val_dataset = Subset(dataset, val_indices)\n",
    "test_dataset = Subset(dataset, test_indices)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, collate_fn=lambda x: tuple(zip(*x)))\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4, collate_fn=lambda x: tuple(zip(*x)))\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4, collate_fn=lambda x: tuple(zip(*x)))\n",
    "\n",
    "print(f\"Tama√±o del conjunto de entrenamiento: {len(train_dataset)}\")\n",
    "print(f\"Tama√±o del conjunto de validaci√≥n: {len(val_dataset)}\")\n",
    "print(f\"Tama√±o del conjunto de prueba: {len(test_dataset)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
